{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rHLcriKWLRe4"
   },
   "source": [
    "# Assignment 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:chocolate\"> Submission requirements </span>\n",
    "\n",
    "Your work will not be graded if your notebook doesn't include output. In other words, <span style=\"color:red\"> make sure to rerun your notebook before submitting to Gradescope </span> (Note: if you are using Google Colab: go to Edit > Notebook Settings  and uncheck Omit code cell output when saving this notebook, otherwise the output is not printed).\n",
    "\n",
    "Additional points may be deducted if these requirements are not met:\n",
    "\n",
    "    \n",
    "* Comment your code;\n",
    "* Each graph should have a title, labels for each axis, and (if needed) a legend. Each graph should be understandable on its own;\n",
    "* Try and minimize the use of the global namespace (meaning, keep things inside functions).\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7X58hOMTUH-w"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_1d_data(num_examples, w, b, bound):\n",
    "  \"\"\"Create X, Y data with a linear relationship with added noise.\n",
    "\n",
    "  Args:\n",
    "    num_examples: number of examples to generate\n",
    "    w: desired slope\n",
    "    b: desired intercept\n",
    "    bound: lower and upper boundary of the data interval\n",
    "\n",
    "  Returns:\n",
    "    X and Y with shape (num_examples)\n",
    "  \"\"\"\n",
    "  np.random.seed(4)  # consistent random number generation\n",
    "  X = np.arange(num_examples)\n",
    "  deltas = np.random.uniform(low=-bound, high=bound, size=X.shape) # added noise\n",
    "  Y = b + deltas + w * X\n",
    "\n",
    "  return X, Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Step 1: Data ingestion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xbCRG2-uUKCT"
   },
   "source": [
    "Supervised learning is all about learning to make predictions: given an input $x$ (e.g. home square footage), can we produce an output $\\hat{y}$ (e.g. estimated value) as close to the actual observed output $y$ (e.g. sale price) as possible. Note that the \"hat\" above $y$ is used to denote an estimated or predicted value.\n",
    "\n",
    "Let's start by generating some artificial data. We'll create a vector of inputs, $X$, and a corresponding vector of target outputs $Y$. In general, we'll refer to invidual examples with a lowercase ($x$), and a vector or matrix containing multiple examples with a capital ($X$)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:chocolate\">Exercise 1:</span> Create data (10 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create artificial data using the function <span style=\"color:chocolate\">create_1d_data()</span> defined at the top of this notebook. Set the following argument values:\n",
    "- number of examples = 70;\n",
    "- slope (w) = 2;\n",
    "- intercept (b) = 1;\n",
    "- bound = 1.\n",
    "\n",
    "Denote the output by X and Y. Print the shape and the first 10 elements for each object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Step 2: Data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given the simplicity of the data (just one feature in X), our sole task here is to divide the data into training and test sets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:chocolate\">Exercise 2:</span> Data splits (10 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the <span style=\"color:chocolate\">train_test_split()</span> method available in scikit-learn:\n",
    "1. Split the (X,Y) data into training and test paritions by setting test_size=0.3 and random_state=1234. All the other arguments of the method are set to default values. Name the resulting arrays X_train, X_test, Y_train, Y_test;\n",
    "2. Print the shape of each array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Step 3: Exploratory data analysis (EDA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EDA helps us to gain insights into the distribution and characteristics of the dataset we are dealing with. \n",
    "This understanding is fundamental for making informed decisions regarding:\n",
    "- data cleaning;\n",
    "- feature selection;\n",
    "- model building;\n",
    "- model evaluation, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:chocolate\">Exercise 3:</span> Plots (10 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Generate a scatter plot displaying the X_train data along the x-axis and the Y_train data along the y-axis, ensuring clear labeling of both axes. Add a title \"Exploratory Data Analysis: Training Data\" and a legend \"observed training data\" to the plot;\n",
    "2. Enhance the plot by incorporating a vertical red line to denote the mean value of X_train. Accompany it with a legend clarifying the meaning of the line and the mean value of X_train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Step 4: Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, our objective is to propose models to describe the data generation process. Remember a model is a function that takes an input $x$ and produces a prediction $\\hat{y}$.\n",
    "\n",
    "Let's consider two possible models for this data:\n",
    "1. $M_1(x) = 5+x$ \n",
    "2. $M_2(x) = 1+2x$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W6coKbXSpXOz"
   },
   "source": [
    "### <span style=\"color:chocolate\">Exercise 4:</span> Models for data (10 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Compute the predictions of models $M_1$ and $M_2$ for the values in X_train. These predictions should be vectors of the same shape as Y_train. Call these predictions M1_hat_train and M2_hat_train. Hint: the \"learned\" parameters are alredy provided to you;\n",
    "2. Plot the prediction lines of these two models overlayed on the observed data (X_train, Y_train). Note: you will generate only one plot. Make sure to include axes names, titles and legend. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AHIY5kNXUIAP"
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Step 5: Evaluation and Generalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NH-0soZiWx9x"
   },
   "source": [
    "How good are our models? Intuitively, the better the model, the more closely it fits the data we have. That is, for each $x$, we'll compare $y$, the true value, with $\\hat{y}$, the predicted value. This comparison is often called the *loss* or the *error*. One common such comparison is *squared error*: $(y-\\hat{y})^2$. Averaging over all our data points, we get the *mean squared error*:\n",
    "\n",
    "\\begin{equation}\n",
    "\\textit{MSE} = \\frac{1}{n} \\sum_{y_i \\in Y}(y_i - \\hat{y}_i)^2\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How well do our models generalize? The test dataset serves as a proxy for unseen data in real-world applications. By evaluating the model on the test data, you can assess its ability to generalize beyond the training data. This ensures that the model can make accurate predictions on new data it hasn't seen during training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_AyY2DpxYLI0"
   },
   "source": [
    "### <span style=\"color:chocolate\">Exercise 5:</span> Computing MSE (20 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Write a function for computing the MSE metric based on the provided definition;\n",
    "2. Utilizing this function, calculate the training data MSE for the two models, $M_1$ and $M_2$.\n",
    "3. Comment on which model fits the training data better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uCeAfI5mW9sg"
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "def MSE(true_values, predicted_values):\n",
    "  \"\"\"Return the MSE between true_values and predicted values.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:chocolate\">Exercise 6:</span> Generalization (15 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Compute the predictions of models $M_1$ and $M_2$ for the values in X_test. These predictions should be vectors of the same shape as Y_test. Call these predictions M1_hat_test and M2_hat_test.\n",
    "2. Calculate the test data MSE for the two models, $M_1$ and $M_2$, using the <span style=\"color:chocolate\">MSE()</span> function defined above.\n",
    "3. Does the model you chose in Exercise 5 generalize well?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:chocolate\">Exercise 7:</span> More features (25 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Fit an 8-th degree polynomial to (X_train, Y_train). Call the predictions of this model M3_hat_train. Hint: see <span style=\"color:chocolate\">np.polyfit()</span> for details.\n",
    "2. Plot the prediction lines of the $M_3$ overlayed on the observed data (X_train, Y_train). Note: you will generate only one plot. Make sure to include axes names, titles and legend. \n",
    "3. Calculate the training data MSE for the $M_3$ model using the <span style=\"color:chocolate\">MSE()</span> function defined above.\n",
    "4. Does model $M_3$ do better than your chosen model in Exercise 5 at predicting the labels for new unseen data? Hint: your new unseen data is the test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "#### <span style=\"color:chocolate\">Additional practice question</span> (not graded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Would you perform EDA on the test dataset?\n",
    "1. Why or why not?\n",
    "2. Provide a link to a paper/article to support your answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR ANSWER HERE"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "copyright",
    "xxOhpvdW6TbX",
    "exercise-1-key-1",
    "43ZTSJEc526U",
    "exercise-5-key-1",
    "ubHispCAA_5u",
    "exercise-6-key-1",
    "5p1IvWjfEjqm",
    "exercise-9-key-1"
   ],
   "name": "01 Introduction.ipynb",
   "private_outputs": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
