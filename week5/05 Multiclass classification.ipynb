{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "67abc16d",
   "metadata": {},
   "source": [
    "# Assignment 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a72deb5",
   "metadata": {},
   "source": [
    "### <span style=\"color:chocolate\"> Submission requirements </span>\n",
    "\n",
    "Your work will not be graded if your notebook doesn't include output. In other words, <span style=\"color:red\"> make sure to rerun your notebook before submitting to Gradescope </span> (Note: if you are using Google Colab: go to Edit > Notebook Settings  and uncheck Omit code cell output when saving this notebook, otherwise the output is not printed).\n",
    "\n",
    "Additional points may be deducted if these requirements are not met:\n",
    "    \n",
    "* Comment your code;\n",
    "* Each graph should have a title, labels for each axis, and (if needed) a legend. Each graph should be understandable on its own;\n",
    "* Try and minimize the use of the global namespace (meaning, keep things inside functions).\n",
    "\n",
    "Additional notes:\n",
    "\n",
    "* Please note that in this assignment, students are expected to work independently. As a result, no two solutions should look identical in terms of coding;\n",
    "* You may import any libraries you need to complete the assignment. However, you must implement the model using TensorFlow (do not use PyTorch);\n",
    "* Follow the same steps/idea as in Assignment 4; the difference here is that you extend a logistic model to more than two classes;\n",
    "* <span style=\"color:chocolate\"> Focus on the execution of the task rather than model performance </span> (this is how the TA will grade your work);\n",
    "* Even though the prediction performance for your chosen outcome is low, it doesn't necessarily mean there is something wrong with your implementation. It could also be that the data is not supportive enough for your prediction task... again, focus on the learning opportunity and not the numbers you get;\n",
    "* Your instructional team has extensive experience developing and running ML models. Often, we encounter situations where a model doesn't perform well on a predictive task. This can happen due to the nature of the data or the need for significant tweaking of variables to achieve good results;\n",
    "* Do not spend significantly more time on this task than you did on Assignment 4, unless you wish to experiment and learn more.\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52b6df70",
   "metadata": {},
   "source": [
    "``Objective``\n",
    "* Perform multiclass classification using logistic regression. <span style=\"color:chocolate\"> You will choose the outcome of interest. </span>\n",
    "\n",
    "``Motivation``\n",
    "* Chocolate is one of the most popular candies in the world. Each year, residents of the United States collectively eat more than 2.8 billions pounds (Source: Kaggle). However, not all chocolate bars are created equal! In this assignment, you will have the opportunity to delve into the world of chocolate by choosing your own machine learning task. \n",
    "\n",
    "\n",
    "``Data``\n",
    "\n",
    "* The [Chocolate Bar dataset](https://www.kaggle.com/datasets/rtatman/chocolate-bar-ratings) contains expert ratings of 1,795 individual chocolate bars, along with information on their regional origin, percentage of cocoa, the variety of chocolate bean used and where the beans were grown (Source: Kaggle)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b999fc96",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ce1be241",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "%reset -f\n",
    "from __future__ import print_function\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "import numpy.linalg as nla\n",
    "import pandas as pd\n",
    "import re\n",
    "import six\n",
    "from os.path import join\n",
    "import tensorflow as tf\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras_tuner import HyperParameters\n",
    "\n",
    "# feel free to import other libraries as needed\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "b9839d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f44e88f",
   "metadata": {},
   "source": [
    "### Define functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "fd91c8a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data():\n",
    "    ''''''\n",
    "    # Read data\n",
    "    df = pd.read_csv(\n",
    "        \"https://download.mlcc.google.com/mledu-datasets/flavors_of_cacao.csv\",\n",
    "        sep=\",\",\n",
    "        encoding='latin-1'\n",
    "    )\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "79237ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# temp cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "7a182b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(df):\n",
    "    ''''''\n",
    "    # Set the output display to have one digit for decimal places and limit it to\n",
    "    # printing 15 rows.\n",
    "    pd.options.display.float_format = '{:.2f}'.format\n",
    "    pd.options.display.max_rows = 15\n",
    "    \n",
    "    # Rename the columns.\n",
    "    df.columns = [\n",
    "        'maker', 'specific_origin', 'reference_number',\n",
    "        'review_date', 'cocoa_percent', 'maker_location',\n",
    "        'rating', 'bean_type', 'broad_origin'\n",
    "    ]\n",
    "\n",
    "    # df.dtypes\n",
    "\n",
    "    # Replace empty/null values with \"Blend\"\n",
    "    df['bean_type'] = df['bean_type'].fillna('Blend')\n",
    "\n",
    "    # Cast bean_type to string to remove leading 'u'\n",
    "    df['bean_type'] = df['bean_type'].astype(str)\n",
    "    df['cocoa_percent'] = df['cocoa_percent'].str.strip('%')\n",
    "    df['cocoa_percent'] = pd.to_numeric(df['cocoa_percent'])\n",
    "\n",
    "    # Correct spelling mistakes, and replace city with country name\n",
    "    df['maker_location'] = df['maker_location']\\\n",
    "    .str.replace('Amsterdam', 'Holland')\\\n",
    "    .str.replace('U.K.', 'England')\\\n",
    "    .str.replace('Niacragua', 'Nicaragua')\\\n",
    "    .str.replace('Domincan Republic', 'Dominican Republic')\n",
    "\n",
    "    # Adding this so that Holland and Netherlands map to the same country.\n",
    "    df['maker_location'] = df['maker_location']\\\n",
    "    .str.replace('Holland', 'Netherlands')\n",
    "\n",
    "    def cleanup_spelling_abbrev(text):\n",
    "        replacements = [\n",
    "            ['-', ', '], ['/ ', ', '], ['/', ', '], ['\\(', ', '], [' and', ', '], [' &', ', '], ['\\)', ''],\n",
    "            ['Dom Rep|DR|Domin Rep|Dominican Rep,|Domincan Republic', 'Dominican Republic'],\n",
    "            ['Mad,|Mad$', 'Madagascar, '],\n",
    "            ['PNG', 'Papua New Guinea, '],\n",
    "            ['Guat,|Guat$', 'Guatemala, '],\n",
    "            ['Ven,|Ven$|Venez,|Venez$', 'Venezuela, '],\n",
    "            ['Ecu,|Ecu$|Ecuad,|Ecuad$', 'Ecuador, '],\n",
    "            ['Nic,|Nic$', 'Nicaragua, '],\n",
    "            ['Cost Rica', 'Costa Rica'],\n",
    "            ['Mex,|Mex$', 'Mexico, '],\n",
    "            ['Jam,|Jam$', 'Jamaica, '],\n",
    "            ['Haw,|Haw$', 'Hawaii, '],\n",
    "            ['Gre,|Gre$', 'Grenada, '],\n",
    "            ['Tri,|Tri$', 'Trinidad, '],\n",
    "            ['C Am', 'Central America'],\n",
    "            ['S America', 'South America'],\n",
    "            [', $', ''], [',  ', ', '], [', ,', ', '], ['\\xa0', ' '],[',\\s+', ','],\n",
    "            [' Bali', ',Bali']\n",
    "        ]\n",
    "        for i, j in replacements:\n",
    "            text = re.sub(i, j, text)\n",
    "        return text\n",
    "\n",
    "    df['specific_origin'] = df['specific_origin'].str.replace('.', '').apply(cleanup_spelling_abbrev)\n",
    "\n",
    "    # Cast specific_origin to string\n",
    "    df['specific_origin'] = df['specific_origin'].astype(str)\n",
    "\n",
    "    # Replace null-valued fields with the same value as for specific_origin\n",
    "    df['broad_origin'] = df['broad_origin'].fillna(df['specific_origin'])\n",
    "\n",
    "    # Clean up spelling mistakes and deal with abbreviations\n",
    "    df['broad_origin'] = df['broad_origin'].str.replace('.', '').apply(cleanup_spelling_abbrev)\n",
    "\n",
    "    # Change 'Trinitario, Criollo' to \"Criollo, Trinitario\"\n",
    "    # Check with df['bean_type'].unique()\n",
    "    df.loc[df['bean_type'].isin(['Trinitario, Criollo']),'bean_type'] = \"Criollo, Trinitario\"\n",
    "    # Confirm with df[df['bean_type'].isin(['Trinitario, Criollo'])]\n",
    "\n",
    "    # Fix chocolate maker names\n",
    "    df.loc[df['maker']=='Shattel','maker'] = 'Shattell'\n",
    "    df['maker'] = df['maker'].str.replace(u'Na\\xef\\xbf\\xbdve','Naive')\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "389425c1",
   "metadata": {},
   "source": [
    "---\n",
    "### Step 1: Data ingestion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b454bc04",
   "metadata": {},
   "source": [
    "First, we'll initiate the process of discovering the chocolate world by loading the data. Then, to assist with this assignment, we'll start by tidying up the data a little bit. This involves renaming columns and conducting some string preprocessing tasks, which will be handled by the <span style=\"color:chocolate\">clean_data()</span> function mentioned earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "48857a26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data (1795, 9)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>maker</th>\n",
       "      <th>specific_origin</th>\n",
       "      <th>reference_number</th>\n",
       "      <th>review_date</th>\n",
       "      <th>cocoa_percent</th>\n",
       "      <th>maker_location</th>\n",
       "      <th>rating</th>\n",
       "      <th>bean_type</th>\n",
       "      <th>broad_origin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A. Morin</td>\n",
       "      <td>Agua Grande</td>\n",
       "      <td>1876</td>\n",
       "      <td>2016</td>\n",
       "      <td>63.00</td>\n",
       "      <td>France</td>\n",
       "      <td>3.75</td>\n",
       "      <td>Blend</td>\n",
       "      <td>Sao Tome</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A. Morin</td>\n",
       "      <td>Kpime</td>\n",
       "      <td>1676</td>\n",
       "      <td>2015</td>\n",
       "      <td>70.00</td>\n",
       "      <td>France</td>\n",
       "      <td>2.75</td>\n",
       "      <td>Blend</td>\n",
       "      <td>Togo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A. Morin</td>\n",
       "      <td>Atsane</td>\n",
       "      <td>1676</td>\n",
       "      <td>2015</td>\n",
       "      <td>70.00</td>\n",
       "      <td>France</td>\n",
       "      <td>3.00</td>\n",
       "      <td>Blend</td>\n",
       "      <td>Togo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A. Morin</td>\n",
       "      <td>Akata</td>\n",
       "      <td>1680</td>\n",
       "      <td>2015</td>\n",
       "      <td>70.00</td>\n",
       "      <td>France</td>\n",
       "      <td>3.50</td>\n",
       "      <td>Blend</td>\n",
       "      <td>Togo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A. Morin</td>\n",
       "      <td>Quilla</td>\n",
       "      <td>1704</td>\n",
       "      <td>2015</td>\n",
       "      <td>70.00</td>\n",
       "      <td>France</td>\n",
       "      <td>3.50</td>\n",
       "      <td>Blend</td>\n",
       "      <td>Peru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1790</th>\n",
       "      <td>Zotter</td>\n",
       "      <td>Peru</td>\n",
       "      <td>647</td>\n",
       "      <td>2011</td>\n",
       "      <td>70.00</td>\n",
       "      <td>Austria</td>\n",
       "      <td>3.75</td>\n",
       "      <td>Blend</td>\n",
       "      <td>Peru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1791</th>\n",
       "      <td>Zotter</td>\n",
       "      <td>Congo</td>\n",
       "      <td>749</td>\n",
       "      <td>2011</td>\n",
       "      <td>65.00</td>\n",
       "      <td>Austria</td>\n",
       "      <td>3.00</td>\n",
       "      <td>Forastero</td>\n",
       "      <td>Congo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1792</th>\n",
       "      <td>Zotter</td>\n",
       "      <td>Kerala State</td>\n",
       "      <td>749</td>\n",
       "      <td>2011</td>\n",
       "      <td>65.00</td>\n",
       "      <td>Austria</td>\n",
       "      <td>3.50</td>\n",
       "      <td>Forastero</td>\n",
       "      <td>India</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1793</th>\n",
       "      <td>Zotter</td>\n",
       "      <td>Kerala State</td>\n",
       "      <td>781</td>\n",
       "      <td>2011</td>\n",
       "      <td>62.00</td>\n",
       "      <td>Austria</td>\n",
       "      <td>3.25</td>\n",
       "      <td>Blend</td>\n",
       "      <td>India</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1794</th>\n",
       "      <td>Zotter</td>\n",
       "      <td>Brazil,Mitzi Blue</td>\n",
       "      <td>486</td>\n",
       "      <td>2010</td>\n",
       "      <td>65.00</td>\n",
       "      <td>Austria</td>\n",
       "      <td>3.00</td>\n",
       "      <td>Blend</td>\n",
       "      <td>Brazil</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1795 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         maker    specific_origin  reference_number  review_date  \\\n",
       "0     A. Morin        Agua Grande              1876         2016   \n",
       "1     A. Morin              Kpime              1676         2015   \n",
       "2     A. Morin             Atsane              1676         2015   \n",
       "3     A. Morin              Akata              1680         2015   \n",
       "4     A. Morin             Quilla              1704         2015   \n",
       "...        ...                ...               ...          ...   \n",
       "1790    Zotter               Peru               647         2011   \n",
       "1791    Zotter              Congo               749         2011   \n",
       "1792    Zotter       Kerala State               749         2011   \n",
       "1793    Zotter       Kerala State               781         2011   \n",
       "1794    Zotter  Brazil,Mitzi Blue               486         2010   \n",
       "\n",
       "      cocoa_percent maker_location  rating  bean_type broad_origin  \n",
       "0             63.00         France    3.75      Blend     Sao Tome  \n",
       "1             70.00         France    2.75      Blend         Togo  \n",
       "2             70.00         France    3.00      Blend         Togo  \n",
       "3             70.00         France    3.50      Blend         Togo  \n",
       "4             70.00         France    3.50      Blend         Peru  \n",
       "...             ...            ...     ...        ...          ...  \n",
       "1790          70.00        Austria    3.75      Blend         Peru  \n",
       "1791          65.00        Austria    3.00  Forastero        Congo  \n",
       "1792          65.00        Austria    3.50  Forastero        India  \n",
       "1793          62.00        Austria    3.25      Blend        India  \n",
       "1794          65.00        Austria    3.00      Blend       Brazil  \n",
       "\n",
       "[1795 rows x 9 columns]"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = clean_data(read_data())\n",
    "print('Shape of data', df.shape)\n",
    "df.head(n=30)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c3be38f",
   "metadata": {},
   "source": [
    "### <span style=\"color:chocolate\">Exercise 1:</span> Getting to know the data (5 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed93cfb1",
   "metadata": {},
   "source": [
    "Answer the following questions:\n",
    "    \n",
    "1. How many columns does the dataset contain?\n",
    "2. How many rows are there in the dataset?\n",
    "3. What are the column names?\n",
    "4. List the number of unique values for each column in the data;\n",
    "5. What are the unique cocoa_percent values?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "2fa25981",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataset has 9 columns.\n",
      "The dataset has 1795 rows.\n",
      "--------------------------------------------------\n",
      "The column names are:\n",
      "maker\n",
      "specific_origin\n",
      "reference_number\n",
      "review_date\n",
      "cocoa_percent\n",
      "maker_location\n",
      "rating\n",
      "bean_type\n",
      "broad_origin\n",
      "--------------------------------------------------\n",
      "The number of unique values in each column:\n",
      "Unique values in 'maker': 414\n",
      "Unique values in 'specific_origin': 1038\n",
      "Unique values in 'reference_number': 440\n",
      "Unique values in 'review_date': 12\n",
      "Unique values in 'cocoa_percent': 45\n",
      "Unique values in 'maker_location': 58\n",
      "Unique values in 'rating': 13\n",
      "Unique values in 'bean_type': 39\n",
      "Unique values in 'broad_origin': 160\n",
      "--------------------------------------------------\n",
      "'cocoa_percent' has 45 unique values.\n"
     ]
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "\n",
    "print(f\"The dataset has {df.shape[1]} columns.\")\n",
    "print(f\"The dataset has {df.shape[0]} rows.\")\n",
    "\n",
    "print(50*'-')\n",
    "print(\"The column names are:\")\n",
    "for col_name in df.columns:\n",
    "    print(col_name)\n",
    "#print(f\"The column names are:\\n{[print(col_name) for col_name in df.columns]}\")\n",
    "\n",
    "print(50*'-')\n",
    "print(\"The number of unique values in each column:\")\n",
    "for col_name in df.columns:\n",
    "    print(f\"Unique values in '{col_name}': {len(df[col_name].unique())}\")\n",
    "#len(df.maker.unique())\n",
    "#df.columns\n",
    "print(50*'-')\n",
    "print(f\"'cocoa_percent' has {len(df.cocoa_percent.unique())} unique values.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2deb7815",
   "metadata": {},
   "source": [
    "### <span style=\"color:chocolate\">Exercise 2:</span> Choosing the prediction task (5 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "858aaf43",
   "metadata": {},
   "source": [
    "Now that you’ve explored the data, choose a multiclass outcome (anything except \"ratings\") that you’re interested in predicting. Note: The outcome should have <span style=\"color:chocolate\">at least 3 classes</span>!\n",
    "\n",
    "If your chosen outcome variable requires preprocessing, go ahead and handle that below. For instance, you might choose to predict \"cocoa_percent\". Discretizing it into \"0=low,\" \"1=medium,\" and \"2=high\" makes it easier to work with/interpret the results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97c9b3e0",
   "metadata": {},
   "source": [
    "Your answer here: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "63cf0526-3e99-4a59-ade9-d5935f41a035",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1795 entries, 0 to 1794\n",
      "Data columns (total 9 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   maker             1795 non-null   object \n",
      " 1   specific_origin   1795 non-null   object \n",
      " 2   reference_number  1795 non-null   int64  \n",
      " 3   review_date       1795 non-null   int64  \n",
      " 4   cocoa_percent     1795 non-null   float64\n",
      " 5   maker_location    1795 non-null   object \n",
      " 6   rating            1795 non-null   float64\n",
      " 7   bean_type         1795 non-null   object \n",
      " 8   broad_origin      1795 non-null   object \n",
      "dtypes: float64(2), int64(2), object(5)\n",
      "memory usage: 126.3+ KB\n",
      "maker_location\n",
      "U.S.A.         764\n",
      "France         156\n",
      "Canada         125\n",
      "England         96\n",
      "Italy           63\n",
      "              ... \n",
      "India            1\n",
      "Philippines      1\n",
      "Ghana            1\n",
      "Eucador          1\n",
      "Suriname         1\n",
      "Name: count, Length: 58, dtype: int64\n",
      "['France' 'U.S.A.' 'Fiji' 'Ecuador' 'Mexico' 'Switzerland' 'Netherlands'\n",
      " 'Spain' 'Peru' 'Canada' 'Italy' 'Brazil' 'England' 'Australia' 'Wales'\n",
      " 'Belgium' 'Germany' 'Russia' 'Puerto Rico' 'Venezuela' 'Colombia' 'Japan'\n",
      " 'New Zealand' 'Costa Rica' 'South Korea' 'Scotland' 'Martinique'\n",
      " 'Sao Tome' 'Argentina' 'Guatemala' 'South Africa' 'Bolivia' 'St. Lucia'\n",
      " 'Portugal' 'Singapore' 'Denmark' 'Vietnam' 'Grenada' 'Israel' 'India'\n",
      " 'Czech Republic' 'Dominican Republic' 'Finland' 'Madagascar'\n",
      " 'Philippines' 'Sweden' 'Poland' 'Austria' 'Honduras' 'Nicaragua'\n",
      " 'Lithuania' 'Chile' 'Ghana' 'Iceland' 'Eucador' 'Hungary' 'Suriname'\n",
      " 'Ireland']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "maker_location\n",
       "U.S.A.         764\n",
       "France         156\n",
       "Canada         125\n",
       "England         96\n",
       "Italy           63\n",
       "Ecuador         54\n",
       "Australia       49\n",
       "Belgium         40\n",
       "Switzerland     38\n",
       "Germany         35\n",
       "Austria         26\n",
       "Spain           25\n",
       "Colombia        23\n",
       "Hungary         22\n",
       "Venezuela       20\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "df.info()\n",
    "print(df.maker_location.value_counts())\n",
    "#fig, ax = plt.subplots(figsize=(25, 10))\n",
    "#ax.hist(df.maker_location, bins=58)\n",
    "\n",
    "print(df.maker_location.unique())\n",
    "#plt.xticks(df.maker_location, rotation=90)\n",
    "\n",
    "a = df.maker_location.value_counts().sort_values(ascending=False).head(20)\n",
    "a.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "8563eaa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "region_mapping = {\n",
    "    # North America (Canada, USA, Mexico)\n",
    "    'U.S.A.': 'North America',\n",
    "    'Canada': 'North America',\n",
    "    'Mexico': 'North America',\n",
    "\n",
    "    # Western Europe (including Italy)\n",
    "    'France': 'Western Europe',\n",
    "    'Switzerland': 'Western Europe',\n",
    "    'Netherlands': 'Western Europe',\n",
    "    'Spain': 'Western Europe',\n",
    "    'Italy': 'Western Europe',\n",
    "    'Belgium': 'Western Europe',\n",
    "    'Germany': 'Western Europe',\n",
    "    'England': 'Western Europe',\n",
    "    'Wales': 'Western Europe',\n",
    "    'Scotland': 'Western Europe',\n",
    "    'Portugal': 'Western Europe',\n",
    "    'Denmark': 'Western Europe',\n",
    "    'Sweden': 'Western Europe',\n",
    "    'Austria': 'Western Europe',\n",
    "    'Finland': 'Western Europe',\n",
    "    'Iceland': 'Western Europe',\n",
    "    'Ireland': 'Western Europe',\n",
    "\n",
    "    # Rest of the World (All others)\n",
    "    'Poland': 'Rest of the World',   # Central/Eastern Europe\n",
    "    'Hungary': 'Rest of the World',  # Central Europe\n",
    "    'Czech Republic': 'Rest of the World',\n",
    "    'Lithuania': 'Rest of the World',  # Baltic region\n",
    "    'Russia': 'Rest of the World',  # Eastern Europe\n",
    "    'Costa Rica': 'Rest of the World',  # Central America\n",
    "    'Puerto Rico': 'Rest of the World',\n",
    "    'Honduras': 'Rest of the World',\n",
    "    'Nicaragua': 'Rest of the World',\n",
    "    'Guatemala': 'Rest of the World',\n",
    "    'Dominican Republic': 'Rest of the World',\n",
    "    'Fiji': 'Rest of the World',\n",
    "    'Ecuador': 'Rest of the World',\n",
    "    'Peru': 'Rest of the World',\n",
    "    'Brazil': 'Rest of the World',\n",
    "    'Venezuela': 'Rest of the World',\n",
    "    'Colombia': 'Rest of the World',\n",
    "    'Japan': 'Rest of the World',\n",
    "    'New Zealand': 'Rest of the World',\n",
    "    'South Korea': 'Rest of the World',\n",
    "    'Martinique': 'Rest of the World',\n",
    "    'Sao Tome': 'Rest of the World',\n",
    "    'Argentina': 'Rest of the World',\n",
    "    'South Africa': 'Rest of the World',\n",
    "    'Bolivia': 'Rest of the World',\n",
    "    'St. Lucia': 'Rest of the World',\n",
    "    'Singapore': 'Rest of the World',\n",
    "    'Vietnam': 'Rest of the World',\n",
    "    'Grenada': 'Rest of the World',\n",
    "    'Israel': 'Rest of the World',\n",
    "    'India': 'Rest of the World',\n",
    "    'Madagascar': 'Rest of the World',\n",
    "    'Philippines': 'Rest of the World',\n",
    "    'Chile': 'Rest of the World',\n",
    "    'Ghana': 'Rest of the World',\n",
    "    'Eucador': 'Rest of the World',  # Assuming typo for \"Ecuador\"\n",
    "    'Suriname': 'Rest of the World'\n",
    "}\n",
    "\n",
    "df['maker_region'] = df['maker_location'].map(region_mapping).fillna('Rest of the World')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "3584ebf4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "maker_region\n",
       "North America        893\n",
       "Western Europe       530\n",
       "Rest of the World    372\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.maker_region.value_counts()\n",
    "#df.maker_region.isna().sum()\n",
    "#df.maker_location.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "f95ba2e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1795 entries, 0 to 1794\n",
      "Data columns (total 12 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   maker              1795 non-null   object \n",
      " 1   specific_origin    1795 non-null   object \n",
      " 2   reference_number   1795 non-null   int64  \n",
      " 3   review_date        1795 non-null   int64  \n",
      " 4   cocoa_percent      1795 non-null   float64\n",
      " 5   maker_location     1795 non-null   object \n",
      " 6   rating             1795 non-null   float64\n",
      " 7   bean_type          1795 non-null   object \n",
      " 8   broad_origin       1795 non-null   object \n",
      " 9   north_america      1795 non-null   int64  \n",
      " 10  rest_of_the_world  1795 non-null   int64  \n",
      " 11  west_europe        1795 non-null   int64  \n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 168.4+ KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>maker</th>\n",
       "      <th>specific_origin</th>\n",
       "      <th>reference_number</th>\n",
       "      <th>review_date</th>\n",
       "      <th>cocoa_percent</th>\n",
       "      <th>maker_location</th>\n",
       "      <th>rating</th>\n",
       "      <th>bean_type</th>\n",
       "      <th>broad_origin</th>\n",
       "      <th>north_america</th>\n",
       "      <th>rest_of_the_world</th>\n",
       "      <th>west_europe</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A. Morin</td>\n",
       "      <td>Agua Grande</td>\n",
       "      <td>1876</td>\n",
       "      <td>2016</td>\n",
       "      <td>63.00</td>\n",
       "      <td>France</td>\n",
       "      <td>3.75</td>\n",
       "      <td>Blend</td>\n",
       "      <td>Sao Tome</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A. Morin</td>\n",
       "      <td>Kpime</td>\n",
       "      <td>1676</td>\n",
       "      <td>2015</td>\n",
       "      <td>70.00</td>\n",
       "      <td>France</td>\n",
       "      <td>2.75</td>\n",
       "      <td>Blend</td>\n",
       "      <td>Togo</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A. Morin</td>\n",
       "      <td>Atsane</td>\n",
       "      <td>1676</td>\n",
       "      <td>2015</td>\n",
       "      <td>70.00</td>\n",
       "      <td>France</td>\n",
       "      <td>3.00</td>\n",
       "      <td>Blend</td>\n",
       "      <td>Togo</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A. Morin</td>\n",
       "      <td>Akata</td>\n",
       "      <td>1680</td>\n",
       "      <td>2015</td>\n",
       "      <td>70.00</td>\n",
       "      <td>France</td>\n",
       "      <td>3.50</td>\n",
       "      <td>Blend</td>\n",
       "      <td>Togo</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A. Morin</td>\n",
       "      <td>Quilla</td>\n",
       "      <td>1704</td>\n",
       "      <td>2015</td>\n",
       "      <td>70.00</td>\n",
       "      <td>France</td>\n",
       "      <td>3.50</td>\n",
       "      <td>Blend</td>\n",
       "      <td>Peru</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      maker specific_origin  reference_number  review_date  cocoa_percent  \\\n",
       "0  A. Morin     Agua Grande              1876         2016          63.00   \n",
       "1  A. Morin           Kpime              1676         2015          70.00   \n",
       "2  A. Morin          Atsane              1676         2015          70.00   \n",
       "3  A. Morin           Akata              1680         2015          70.00   \n",
       "4  A. Morin          Quilla              1704         2015          70.00   \n",
       "\n",
       "  maker_location  rating bean_type broad_origin  north_america  \\\n",
       "0         France    3.75     Blend     Sao Tome              0   \n",
       "1         France    2.75     Blend         Togo              0   \n",
       "2         France    3.00     Blend         Togo              0   \n",
       "3         France    3.50     Blend         Togo              0   \n",
       "4         France    3.50     Blend         Peru              0   \n",
       "\n",
       "   rest_of_the_world  west_europe  \n",
       "0                  0            1  \n",
       "1                  0            1  \n",
       "2                  0            1  \n",
       "3                  0            1  \n",
       "4                  0            1  "
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_encoded = pd.get_dummies(df, columns=['maker_region'])\n",
    "\n",
    "#one_hot_cols = [col in df_encoded.columns if ''\n",
    "df_encoded.rename(columns={\n",
    "                            'maker_region_North America': 'north_america',\n",
    "                            'maker_region_Western Europe': 'west_europe',\n",
    "                            'maker_region_Rest of the World': 'rest_of_the_world'\n",
    "                                },                  \n",
    "                inplace=True)\n",
    "\n",
    "outcome_cols = ['north_america', 'west_europe', 'rest_of_the_world']\n",
    "df_encoded[outcome_cols] = df_encoded[outcome_cols].astype(int)\n",
    "df_encoded.info()\n",
    "df_encoded.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "5ae2d330",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bean_type\n",
       "Blend                     929\n",
       "Trinitario                419\n",
       "Criollo                   153\n",
       "Forastero                  87\n",
       "Forastero (Nacional)       52\n",
       "Criollo, Trinitario        48\n",
       "Forastero (Arriba)         37\n",
       "Criollo (Porcelana)        10\n",
       "Forastero (Parazinho)       8\n",
       "Forastero (Arriba) ASS      6\n",
       "Beniano                     3\n",
       "Matina                      3\n",
       "Nacional (Arriba)           3\n",
       "EET                         3\n",
       "Criollo (Ocumare 61)        2\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Decision\n",
    "# Encode bean types to 3 using one-hot \n",
    "\n",
    "df_encoded.specific_origin.value_counts()\n",
    "\n",
    "df_encoded.broad_origin.value_counts().head(15)\n",
    "\n",
    "df_encoded.bean_type.value_counts().head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "8b380c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "bean_type_mapping = {'Blend': 'Blend',\n",
    "                     'Trinitario': 'Trinitario'}\n",
    "df_encoded['bean_type'] = df_encoded['bean_type'].map(bean_type_mapping).fillna('other')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "2947198f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bean_type\n",
       "Blend         929\n",
       "other         447\n",
       "Trinitario    419\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_encoded.bean_type.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "78604e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_encoded = pd.get_dummies(df_encoded, columns=['bean_type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "8e5e7fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_encoded.columns[-1]\n",
    "df_encoded.drop(columns='bean_type_other', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "88410d8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>maker</th>\n",
       "      <th>specific_origin</th>\n",
       "      <th>reference_number</th>\n",
       "      <th>review_date</th>\n",
       "      <th>cocoa_percent</th>\n",
       "      <th>maker_location</th>\n",
       "      <th>rating</th>\n",
       "      <th>broad_origin</th>\n",
       "      <th>north_america</th>\n",
       "      <th>rest_of_the_world</th>\n",
       "      <th>west_europe</th>\n",
       "      <th>blend_bean</th>\n",
       "      <th>trinitario_bean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A. Morin</td>\n",
       "      <td>Agua Grande</td>\n",
       "      <td>1876</td>\n",
       "      <td>2016</td>\n",
       "      <td>63.00</td>\n",
       "      <td>France</td>\n",
       "      <td>3.75</td>\n",
       "      <td>Sao Tome</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A. Morin</td>\n",
       "      <td>Kpime</td>\n",
       "      <td>1676</td>\n",
       "      <td>2015</td>\n",
       "      <td>70.00</td>\n",
       "      <td>France</td>\n",
       "      <td>2.75</td>\n",
       "      <td>Togo</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A. Morin</td>\n",
       "      <td>Atsane</td>\n",
       "      <td>1676</td>\n",
       "      <td>2015</td>\n",
       "      <td>70.00</td>\n",
       "      <td>France</td>\n",
       "      <td>3.00</td>\n",
       "      <td>Togo</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A. Morin</td>\n",
       "      <td>Akata</td>\n",
       "      <td>1680</td>\n",
       "      <td>2015</td>\n",
       "      <td>70.00</td>\n",
       "      <td>France</td>\n",
       "      <td>3.50</td>\n",
       "      <td>Togo</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A. Morin</td>\n",
       "      <td>Quilla</td>\n",
       "      <td>1704</td>\n",
       "      <td>2015</td>\n",
       "      <td>70.00</td>\n",
       "      <td>France</td>\n",
       "      <td>3.50</td>\n",
       "      <td>Peru</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1790</th>\n",
       "      <td>Zotter</td>\n",
       "      <td>Peru</td>\n",
       "      <td>647</td>\n",
       "      <td>2011</td>\n",
       "      <td>70.00</td>\n",
       "      <td>Austria</td>\n",
       "      <td>3.75</td>\n",
       "      <td>Peru</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1791</th>\n",
       "      <td>Zotter</td>\n",
       "      <td>Congo</td>\n",
       "      <td>749</td>\n",
       "      <td>2011</td>\n",
       "      <td>65.00</td>\n",
       "      <td>Austria</td>\n",
       "      <td>3.00</td>\n",
       "      <td>Congo</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1792</th>\n",
       "      <td>Zotter</td>\n",
       "      <td>Kerala State</td>\n",
       "      <td>749</td>\n",
       "      <td>2011</td>\n",
       "      <td>65.00</td>\n",
       "      <td>Austria</td>\n",
       "      <td>3.50</td>\n",
       "      <td>India</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1793</th>\n",
       "      <td>Zotter</td>\n",
       "      <td>Kerala State</td>\n",
       "      <td>781</td>\n",
       "      <td>2011</td>\n",
       "      <td>62.00</td>\n",
       "      <td>Austria</td>\n",
       "      <td>3.25</td>\n",
       "      <td>India</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1794</th>\n",
       "      <td>Zotter</td>\n",
       "      <td>Brazil,Mitzi Blue</td>\n",
       "      <td>486</td>\n",
       "      <td>2010</td>\n",
       "      <td>65.00</td>\n",
       "      <td>Austria</td>\n",
       "      <td>3.00</td>\n",
       "      <td>Brazil</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1795 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         maker    specific_origin  reference_number  review_date  \\\n",
       "0     A. Morin        Agua Grande              1876         2016   \n",
       "1     A. Morin              Kpime              1676         2015   \n",
       "2     A. Morin             Atsane              1676         2015   \n",
       "3     A. Morin              Akata              1680         2015   \n",
       "4     A. Morin             Quilla              1704         2015   \n",
       "...        ...                ...               ...          ...   \n",
       "1790    Zotter               Peru               647         2011   \n",
       "1791    Zotter              Congo               749         2011   \n",
       "1792    Zotter       Kerala State               749         2011   \n",
       "1793    Zotter       Kerala State               781         2011   \n",
       "1794    Zotter  Brazil,Mitzi Blue               486         2010   \n",
       "\n",
       "      cocoa_percent maker_location  rating broad_origin  north_america  \\\n",
       "0             63.00         France    3.75     Sao Tome              0   \n",
       "1             70.00         France    2.75         Togo              0   \n",
       "2             70.00         France    3.00         Togo              0   \n",
       "3             70.00         France    3.50         Togo              0   \n",
       "4             70.00         France    3.50         Peru              0   \n",
       "...             ...            ...     ...          ...            ...   \n",
       "1790          70.00        Austria    3.75         Peru              0   \n",
       "1791          65.00        Austria    3.00        Congo              0   \n",
       "1792          65.00        Austria    3.50        India              0   \n",
       "1793          62.00        Austria    3.25        India              0   \n",
       "1794          65.00        Austria    3.00       Brazil              0   \n",
       "\n",
       "      rest_of_the_world  west_europe  blend_bean  trinitario_bean  \n",
       "0                     0            1           1                0  \n",
       "1                     0            1           1                0  \n",
       "2                     0            1           1                0  \n",
       "3                     0            1           1                0  \n",
       "4                     0            1           1                0  \n",
       "...                 ...          ...         ...              ...  \n",
       "1790                  0            1           1                0  \n",
       "1791                  0            1           0                0  \n",
       "1792                  0            1           0                0  \n",
       "1793                  0            1           1                0  \n",
       "1794                  0            1           1                0  \n",
       "\n",
       "[1795 rows x 13 columns]"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_encoded.rename(columns={'bean_type_Blend': 'blend_bean',\n",
    "                           'bean_type_Trinitario': 'trinitario_bean'},\n",
    "                    inplace=True)\n",
    "\n",
    "bean_type_cols = ['blend_bean', 'trinitario_bean']\n",
    "\n",
    "df_encoded[bean_type_cols] = df_encoded[bean_type_cols].astype(int)\n",
    "df_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "aed0dfc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Sao Tome', 'Togo', 'Peru', 'Venezuela', 'Cuba', 'Panama',\n",
       "       'Madagascar', 'Brazil', 'Ecuador', 'Colombia', 'Burma',\n",
       "       'Papua New Guinea', 'Bolivia', 'Fiji', 'Mexico', 'Indonesia',\n",
       "       'Trinidad', 'Vietnam', 'Nicaragua', 'Tanzania',\n",
       "       'Dominican Republic', 'Ghana', 'Belize', 'Nine', 'Jamaica',\n",
       "       'Grenada', 'Toscano Black', 'Guatemala', 'Honduras', 'Costa Rica',\n",
       "       'Haiti', 'Congo', 'Philippines', 'Houseblend', 'Malaysia',\n",
       "       'Nature', 'Dominican Republic,Bali', 'Organic Dark',\n",
       "       'Venezuela,Africa,Brasil,Peru,Mexico', 'Gabon', 'Ivory Coast',\n",
       "       'Carribean', 'One Hundred', 'Sri Lanka', 'Blend', 'Puerto Rico',\n",
       "       'Lago di Como,Blu', 'Uganda', 'Blend No 1',\n",
       "       'Philly Blend,5 plantations', 'Kendari', 'Tarakan', 'Maragda',\n",
       "       'Martinique', 'Sao Tome,Principe', 'Sensations Intense', 'Vanuatu',\n",
       "       'Australia', 'Zorzal Reserva,2015 H,Kerchner', 'Liberia',\n",
       "       'Ecuador,Costa Rica', 'West Africa', 'Hawaii', 'Noir', 'Ilblend',\n",
       "       'St Lucia', 'Costa Rica,Venezuela', 'Peru,Madagascar',\n",
       "       'Red Vanilla', 'Venezuela,Trinidad', 'Supremo,SF', 'Dark',\n",
       "       'Trinidad,Tobago', 'Venezuela,Trinidad,Ecuador',\n",
       "       'Epique,Blend No 49', 'Coucher du Soleil', 'Lever du Soleil',\n",
       "       'Onyx', 'Nocturne', 'Complexite', 'Special Maker Reserve',\n",
       "       'Quetzalcoatl', 'Tsaranta', 'Semisweet', 'Campesino w,nibs',\n",
       "       'Trinitario', 'Downtown London', 'Africa meets Latina', 'Amazonas',\n",
       "       'one hundred', 'South America,Africa', 'India',\n",
       "       'Africa,Carribean,Central America', 'Tobago', 'Kuruba', 'Orinoco',\n",
       "       'Venezuela,Indonesia,Ecuador', 'Peru,Ecuador,Venezuela',\n",
       "       'Venezuela,Dominican Republic', 'Excellence ,US Version',\n",
       "       'Colombia,Ecuador', 'Solomon Islands', 'Cacao Nib Crunch',\n",
       "       'Nigeria', 'Peru,Belize', 'Peru,Madagascar,Dominican Republic',\n",
       "       'Brooklyn Blend', 'Papua New Guinea,Vanuatu,Madagascar',\n",
       "       'El Salvador', 'South America', 'Carre Amer', 'Carre Grand Noir',\n",
       "       'Noir Infini', 'Samoa', 'Ghana,Dominican Republic',\n",
       "       'Grand Cru Blend No1,5 yr Anniversary Ed', 'Trinidad,Ecuador',\n",
       "       'Signature Blend', 'Cameroon', 'Venezuela,Java', 'Venezuela,Ghana',\n",
       "       'Indonesia,Ghana', 'Peru,SMartin,Pangoa,nacional', 'Raw',\n",
       "       'Mid Mountain,2014', 'Principe', '100 percent', 'Latino',\n",
       "       'Central,South America', 'Venezuela,Trinidad,Madagascar',\n",
       "       'Carribean,Dominican Republic,Jamaica,Trinidad', 'Nibby',\n",
       "       'Extra Dark', 'Bittersweet', 'Ghana,Madagascar', 'Wasatch',\n",
       "       'Venezuela,Ecuador,Peru,Nicaragua', 'Madagascar,Ecuador',\n",
       "       \"Chef's Blend\",\n",
       "       'Guatemala,Dominican Republic,Peru,Madagascar,Papua New Guinea',\n",
       "       'Peru,Dominican Republic', 'Dominican Republic,Madagascar',\n",
       "       'Grenada,Papua New Guinea,Hawaii,Haiti,Madagascar',\n",
       "       'Madagascar,Java,Papua New Guinea',\n",
       "       'Venezuela,Bolivia,Dominican Republic',\n",
       "       'Dominican Republic,Ecuador,Peru', 'Suriname', 'Peru,Ecuador',\n",
       "       'TCHOPro 605', 'TCHOPro 68', 'Ecuador,Madagascar,Papua New Guinea',\n",
       "       'Ghana,Panama,Ecuador', 'Andoa,Grand Cru blend', 'Caraque',\n",
       "       'Venezuela,Carribean', 'Le Noir Extra Amer', 'House Blend,Batch 2',\n",
       "       'Goddess Blend', 'Amazonas Frucht', 'Indianer,Raw'], dtype=object)"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_encoded.broad_origin.value_counts()\n",
    "\n",
    "\n",
    "#df_encoded.broad_origin = df_encoded.broad_origin.map(region_mapping)\n",
    "df_encoded.broad_origin.value_counts()\n",
    "df_encoded.broad_origin.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50837672",
   "metadata": {},
   "source": [
    "---\n",
    "### Step 2: Data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cc6558b",
   "metadata": {},
   "source": [
    "### <span style=\"color:chocolate\">Exercise 3:</span> Prepare data for modeling (20 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63c5bd4b",
   "metadata": {},
   "source": [
    "Following the format of previous assignments, adhere to the following steps as a minimum:\n",
    "\n",
    "1. Shuffle the dataset;\n",
    "2. Create training, validation, and test datasets using a 60/20/20 split;\n",
    "3. Identify the features of interest;\n",
    "4. Perform necessary cleaning and standarization on the features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "f3b6b87b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>maker</th>\n",
       "      <th>specific_origin</th>\n",
       "      <th>reference_number</th>\n",
       "      <th>review_date</th>\n",
       "      <th>cocoa_percent</th>\n",
       "      <th>maker_location</th>\n",
       "      <th>rating</th>\n",
       "      <th>broad_origin</th>\n",
       "      <th>north_america</th>\n",
       "      <th>rest_of_the_world</th>\n",
       "      <th>west_europe</th>\n",
       "      <th>blend_bean</th>\n",
       "      <th>trinitario_bean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1547</th>\n",
       "      <td>Soma</td>\n",
       "      <td>Black Science Blend 1</td>\n",
       "      <td>607</td>\n",
       "      <td>2010</td>\n",
       "      <td>70.00</td>\n",
       "      <td>Canada</td>\n",
       "      <td>3.75</td>\n",
       "      <td>Dominican Republic,Ecuador,Peru</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1409</th>\n",
       "      <td>Rozsavolgyi</td>\n",
       "      <td>Principe</td>\n",
       "      <td>765</td>\n",
       "      <td>2011</td>\n",
       "      <td>77.00</td>\n",
       "      <td>Hungary</td>\n",
       "      <td>2.75</td>\n",
       "      <td>Principe</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1144</th>\n",
       "      <td>Molucca</td>\n",
       "      <td>Indonesia</td>\n",
       "      <td>1618</td>\n",
       "      <td>2015</td>\n",
       "      <td>70.00</td>\n",
       "      <td>U.S.A.</td>\n",
       "      <td>2.75</td>\n",
       "      <td>Indonesia</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>746</th>\n",
       "      <td>Guido Castagna</td>\n",
       "      <td>Trinidad,Tobago</td>\n",
       "      <td>355</td>\n",
       "      <td>2009</td>\n",
       "      <td>64.00</td>\n",
       "      <td>Italy</td>\n",
       "      <td>3.00</td>\n",
       "      <td>Trinidad,Tobago</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>401</th>\n",
       "      <td>Chocolate Conspiracy</td>\n",
       "      <td>Peru</td>\n",
       "      <td>1259</td>\n",
       "      <td>2014</td>\n",
       "      <td>74.00</td>\n",
       "      <td>U.S.A.</td>\n",
       "      <td>2.75</td>\n",
       "      <td>Peru</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>936</th>\n",
       "      <td>La Maison du Chocolat (Valrhona)</td>\n",
       "      <td>Porcelana,Pariguan</td>\n",
       "      <td>346</td>\n",
       "      <td>2009</td>\n",
       "      <td>69.00</td>\n",
       "      <td>France</td>\n",
       "      <td>3.50</td>\n",
       "      <td>Venezuela</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1378</th>\n",
       "      <td>Ritual</td>\n",
       "      <td>Camino Verde P,2012,Balao,Guayas</td>\n",
       "      <td>967</td>\n",
       "      <td>2012</td>\n",
       "      <td>75.00</td>\n",
       "      <td>U.S.A.</td>\n",
       "      <td>3.25</td>\n",
       "      <td>Ecuador</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>757</th>\n",
       "      <td>Guittard</td>\n",
       "      <td>Trinidad</td>\n",
       "      <td>552</td>\n",
       "      <td>2010</td>\n",
       "      <td>65.00</td>\n",
       "      <td>U.S.A.</td>\n",
       "      <td>3.00</td>\n",
       "      <td>Trinidad</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>622</th>\n",
       "      <td>Enric Rovira (Claudio Corallo)</td>\n",
       "      <td>Terreiro Velho P</td>\n",
       "      <td>565</td>\n",
       "      <td>2010</td>\n",
       "      <td>80.00</td>\n",
       "      <td>Spain</td>\n",
       "      <td>3.25</td>\n",
       "      <td>Sao Tome,Principe</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1629</th>\n",
       "      <td>TCHO</td>\n",
       "      <td>Nutty,beta</td>\n",
       "      <td>284</td>\n",
       "      <td>2008</td>\n",
       "      <td>70.00</td>\n",
       "      <td>U.S.A.</td>\n",
       "      <td>2.50</td>\n",
       "      <td>Peru</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1795 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 maker                   specific_origin  \\\n",
       "1547                              Soma             Black Science Blend 1   \n",
       "1409                       Rozsavolgyi                          Principe   \n",
       "1144                           Molucca                         Indonesia   \n",
       "746                     Guido Castagna                   Trinidad,Tobago   \n",
       "401               Chocolate Conspiracy                              Peru   \n",
       "...                                ...                               ...   \n",
       "936   La Maison du Chocolat (Valrhona)                Porcelana,Pariguan   \n",
       "1378                            Ritual  Camino Verde P,2012,Balao,Guayas   \n",
       "757                           Guittard                          Trinidad   \n",
       "622     Enric Rovira (Claudio Corallo)                  Terreiro Velho P   \n",
       "1629                              TCHO                        Nutty,beta   \n",
       "\n",
       "      reference_number  review_date  cocoa_percent maker_location  rating  \\\n",
       "1547               607         2010          70.00         Canada    3.75   \n",
       "1409               765         2011          77.00        Hungary    2.75   \n",
       "1144              1618         2015          70.00         U.S.A.    2.75   \n",
       "746                355         2009          64.00          Italy    3.00   \n",
       "401               1259         2014          74.00         U.S.A.    2.75   \n",
       "...                ...          ...            ...            ...     ...   \n",
       "936                346         2009          69.00         France    3.50   \n",
       "1378               967         2012          75.00         U.S.A.    3.25   \n",
       "757                552         2010          65.00         U.S.A.    3.00   \n",
       "622                565         2010          80.00          Spain    3.25   \n",
       "1629               284         2008          70.00         U.S.A.    2.50   \n",
       "\n",
       "                         broad_origin  north_america  rest_of_the_world  \\\n",
       "1547  Dominican Republic,Ecuador,Peru              1                  0   \n",
       "1409                         Principe              0                  1   \n",
       "1144                        Indonesia              1                  0   \n",
       "746                   Trinidad,Tobago              0                  0   \n",
       "401                              Peru              1                  0   \n",
       "...                               ...            ...                ...   \n",
       "936                         Venezuela              0                  0   \n",
       "1378                          Ecuador              1                  0   \n",
       "757                          Trinidad              1                  0   \n",
       "622                 Sao Tome,Principe              0                  0   \n",
       "1629                             Peru              1                  0   \n",
       "\n",
       "      west_europe  blend_bean  trinitario_bean  \n",
       "1547            0           0                0  \n",
       "1409            0           0                0  \n",
       "1144            0           1                0  \n",
       "746             1           1                0  \n",
       "401             0           1                0  \n",
       "...           ...         ...              ...  \n",
       "936             1           0                0  \n",
       "1378            0           0                0  \n",
       "757             0           0                1  \n",
       "622             1           0                0  \n",
       "1629            0           1                0  \n",
       "\n",
       "[1795 rows x 13 columns]"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "\n",
    "# Shuffle\n",
    "#indices = range(0, df.shape[0])\n",
    "np.random.seed(19)\n",
    "indices = np.arange(0, df.shape[0])\n",
    "\n",
    "indices\n",
    "shuffled_indices = np.random.permutation(indices)\n",
    "shuffled_indices\n",
    "\n",
    "df_encoded_shuffle = df_encoded.reindex(shuffled_indices)\n",
    "df_encoded_shuffle\n",
    "#df2.bean_type.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "be9fe250",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     maker        specific_origin  reference_number  \\\n",
      "1547                  Soma  Black Science Blend 1               607   \n",
      "1409           Rozsavolgyi               Principe               765   \n",
      "1144               Molucca              Indonesia              1618   \n",
      "746         Guido Castagna        Trinidad,Tobago               355   \n",
      "401   Chocolate Conspiracy                   Peru              1259   \n",
      "\n",
      "      review_date  cocoa_percent maker_location  rating  \\\n",
      "1547         2010          70.00         Canada    3.75   \n",
      "1409         2011          77.00        Hungary    2.75   \n",
      "1144         2015          70.00         U.S.A.    2.75   \n",
      "746          2009          64.00          Italy    3.00   \n",
      "401          2014          74.00         U.S.A.    2.75   \n",
      "\n",
      "                         broad_origin  blend_bean  trinitario_bean  \n",
      "1547  Dominican Republic,Ecuador,Peru           0                0  \n",
      "1409                         Principe           0                0  \n",
      "1144                        Indonesia           1                0  \n",
      "746                   Trinidad,Tobago           1                0  \n",
      "401                              Peru           1                0  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>north_america</th>\n",
       "      <th>west_europe</th>\n",
       "      <th>rest_of_the_world</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1547</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1409</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1144</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>746</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>401</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      north_america  west_europe  rest_of_the_world\n",
       "1547              1            0                  0\n",
       "1409              0            0                  1\n",
       "1144              1            0                  0\n",
       "746               0            1                  0\n",
       "401               1            0                  0"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df_encoded_shuffle.drop(columns=outcome_cols)\n",
    "Y = df_encoded_shuffle[outcome_cols]\n",
    "\n",
    "print(X.head())\n",
    "Y.head()\n",
    "#X_train_val, X_test, Y_train_val, Y_test = \n",
    "#df_encoded_shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "985ea448",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_val, X_test, Y_train_val, Y_test = train_test_split(X, Y, test_size=0.2)\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(X_train_val, Y_train_val, test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "c41bcc1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (1077, 10)\n",
      "X_val shape (359, 10)\n",
      "X_test shape (359, 10)\n",
      "Y_train shape: (1077, 3)\n",
      "Y_val shape (359, 3)\n",
      "Y_test shape (359, 3)\n"
     ]
    }
   ],
   "source": [
    "print('X_train shape:', X_train.shape)\n",
    "print('X_val shape', X_val.shape)\n",
    "print('X_test shape', X_test.shape)\n",
    "\n",
    "print('Y_train shape:', Y_train.shape)\n",
    "print('Y_val shape', Y_val.shape)\n",
    "print('Y_test shape', Y_test.shape)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "188056dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>maker</th>\n",
       "      <th>specific_origin</th>\n",
       "      <th>reference_number</th>\n",
       "      <th>review_date</th>\n",
       "      <th>cocoa_percent</th>\n",
       "      <th>maker_location</th>\n",
       "      <th>rating</th>\n",
       "      <th>broad_origin</th>\n",
       "      <th>blend_bean</th>\n",
       "      <th>trinitario_bean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>444</th>\n",
       "      <td>Compania de Chocolate (Salgado)</td>\n",
       "      <td>Esmeraldas</td>\n",
       "      <td>296</td>\n",
       "      <td>2008</td>\n",
       "      <td>88.00</td>\n",
       "      <td>Argentina</td>\n",
       "      <td>2.75</td>\n",
       "      <td>Ecuador</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1508</th>\n",
       "      <td>Soma</td>\n",
       "      <td>Sambirano Valley,Black Science,B,603070</td>\n",
       "      <td>1820</td>\n",
       "      <td>2016</td>\n",
       "      <td>70.00</td>\n",
       "      <td>Canada</td>\n",
       "      <td>3.50</td>\n",
       "      <td>Madagascar</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>419</th>\n",
       "      <td>Chocovic</td>\n",
       "      <td>Bolivar,Guaranda</td>\n",
       "      <td>117</td>\n",
       "      <td>2007</td>\n",
       "      <td>71.00</td>\n",
       "      <td>Spain</td>\n",
       "      <td>2.50</td>\n",
       "      <td>Ecuador</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1787</th>\n",
       "      <td>Zotter</td>\n",
       "      <td>Santo Domingo</td>\n",
       "      <td>879</td>\n",
       "      <td>2012</td>\n",
       "      <td>70.00</td>\n",
       "      <td>Austria</td>\n",
       "      <td>3.75</td>\n",
       "      <td>Dominican Republic</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1534</th>\n",
       "      <td>Soma</td>\n",
       "      <td>O'ahu</td>\n",
       "      <td>833</td>\n",
       "      <td>2012</td>\n",
       "      <td>70.00</td>\n",
       "      <td>Canada</td>\n",
       "      <td>3.75</td>\n",
       "      <td>Hawaii</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1688</th>\n",
       "      <td>Valrhona</td>\n",
       "      <td>Tainori</td>\n",
       "      <td>327</td>\n",
       "      <td>2009</td>\n",
       "      <td>64.00</td>\n",
       "      <td>France</td>\n",
       "      <td>3.75</td>\n",
       "      <td>Dominican Republic</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1359</th>\n",
       "      <td>Raaka</td>\n",
       "      <td>La Red</td>\n",
       "      <td>785</td>\n",
       "      <td>2011</td>\n",
       "      <td>85.00</td>\n",
       "      <td>U.S.A.</td>\n",
       "      <td>3.50</td>\n",
       "      <td>Dominican Republic</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306</th>\n",
       "      <td>Cacao Prieto</td>\n",
       "      <td>Dominican Republic</td>\n",
       "      <td>641</td>\n",
       "      <td>2011</td>\n",
       "      <td>66.00</td>\n",
       "      <td>U.S.A.</td>\n",
       "      <td>3.75</td>\n",
       "      <td>Dominican Republic</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Alexandre</td>\n",
       "      <td>Makwale Village,Kyela</td>\n",
       "      <td>1944</td>\n",
       "      <td>2017</td>\n",
       "      <td>70.00</td>\n",
       "      <td>Netherlands</td>\n",
       "      <td>3.50</td>\n",
       "      <td>Tanzania</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1145</th>\n",
       "      <td>Molucca</td>\n",
       "      <td>Peru</td>\n",
       "      <td>1618</td>\n",
       "      <td>2015</td>\n",
       "      <td>70.00</td>\n",
       "      <td>U.S.A.</td>\n",
       "      <td>3.25</td>\n",
       "      <td>Peru</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>359 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                maker  \\\n",
       "444   Compania de Chocolate (Salgado)   \n",
       "1508                             Soma   \n",
       "419                          Chocovic   \n",
       "1787                           Zotter   \n",
       "1534                             Soma   \n",
       "...                               ...   \n",
       "1688                         Valrhona   \n",
       "1359                            Raaka   \n",
       "306                      Cacao Prieto   \n",
       "43                          Alexandre   \n",
       "1145                          Molucca   \n",
       "\n",
       "                              specific_origin  reference_number  review_date  \\\n",
       "444                                Esmeraldas               296         2008   \n",
       "1508  Sambirano Valley,Black Science,B,603070              1820         2016   \n",
       "419                          Bolivar,Guaranda               117         2007   \n",
       "1787                            Santo Domingo               879         2012   \n",
       "1534                                    O'ahu               833         2012   \n",
       "...                                       ...               ...          ...   \n",
       "1688                                  Tainori               327         2009   \n",
       "1359                                   La Red               785         2011   \n",
       "306                        Dominican Republic               641         2011   \n",
       "43                      Makwale Village,Kyela              1944         2017   \n",
       "1145                                     Peru              1618         2015   \n",
       "\n",
       "      cocoa_percent maker_location  rating        broad_origin  blend_bean  \\\n",
       "444           88.00      Argentina    2.75             Ecuador           0   \n",
       "1508          70.00         Canada    3.50          Madagascar           0   \n",
       "419           71.00          Spain    2.50             Ecuador           0   \n",
       "1787          70.00        Austria    3.75  Dominican Republic           1   \n",
       "1534          70.00         Canada    3.75              Hawaii           1   \n",
       "...             ...            ...     ...                 ...         ...   \n",
       "1688          64.00         France    3.75  Dominican Republic           1   \n",
       "1359          85.00         U.S.A.    3.50  Dominican Republic           1   \n",
       "306           66.00         U.S.A.    3.75  Dominican Republic           1   \n",
       "43            70.00    Netherlands    3.50            Tanzania           0   \n",
       "1145          70.00         U.S.A.    3.25                Peru           1   \n",
       "\n",
       "      trinitario_bean  \n",
       "444                 0  \n",
       "1508                1  \n",
       "419                 0  \n",
       "1787                0  \n",
       "1534                0  \n",
       "...               ...  \n",
       "1688                0  \n",
       "1359                0  \n",
       "306                 0  \n",
       "43                  0  \n",
       "1145                0  \n",
       "\n",
       "[359 rows x 10 columns]"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "634cce19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features to keep\n",
    "X_train = X_train[['cocoa_percent', 'rating', 'blend_bean', 'trinitario_bean']]\n",
    "\n",
    "X_val = X_val[['cocoa_percent', 'rating', 'blend_bean', 'trinitario_bean']]\n",
    "X_test = X_test[['cocoa_percent', 'rating', 'blend_bean', 'trinitario_bean']]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "c88d3276",
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize(inputs, training_data):\n",
    "    \"\"\"  \n",
    "    Return standardized max-min array \n",
    "    Args:\n",
    "        inputs: a numpy array\n",
    "        training_data: training data (features or outcome) used to calculate location and scale\n",
    "    \"\"\"\n",
    "    return (inputs  - np.min(a=training_data, axis=0, keepdims=True)) / (np.max(a=training_data, axis=0, keepdims=True) - np.min(a=training_data, axis=0, keepdims=True))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "87daba8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.values\n",
    "X_val = X_val.values \n",
    "X_test = X_test.values\n",
    "\n",
    "Y_train = Y_train.values\n",
    "Y_val = Y_val.values \n",
    "Y_test = Y_test.values\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "4507d6f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[76.  ,  3.  ,  0.  ,  0.  ],\n",
       "       [75.  ,  2.5 ,  0.  ,  0.  ],\n",
       "       [90.  ,  2.  ,  0.  ,  0.  ],\n",
       "       ...,\n",
       "       [72.  ,  3.25,  0.  ,  1.  ],\n",
       "       [70.  ,  3.75,  0.  ,  1.  ],\n",
       "       [71.  ,  2.5 ,  0.  ,  1.  ]])"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "e90c8469",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.48275862, 0.75      , 1.        , 0.        ],\n",
       "       [0.22413793, 0.66666667, 1.        , 0.        ],\n",
       "       [0.51724138, 0.58333333, 1.        , 0.        ],\n",
       "       ...,\n",
       "       [0.37931034, 0.66666667, 1.        , 0.        ],\n",
       "       [0.56896552, 0.75      , 0.        , 1.        ],\n",
       "       [0.51724138, 0.66666667, 0.        , 1.        ]])"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_scaled = standardize(X_train, X_train)\n",
    "X_val_scaled = standardize(X_val, X_train)\n",
    "X_test_scaled = standardize(X_test, X_train)\n",
    "X_train_scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fdd4232",
   "metadata": {},
   "source": [
    "---\n",
    "### Step 3: Exploratory data analysis (EDA)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db7896a1",
   "metadata": {},
   "source": [
    "### <span style=\"color:chocolate\">Exercise 4:</span> Plots (20 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9182a26",
   "metadata": {},
   "source": [
    "In line with the structure of previous assignments, execute the following steps:\n",
    "\n",
    "1. Generate a minimum of 4 plots to investigate features and outcome within the training dataset;\n",
    "2. Ensure that each plot includes clear axis labels and titles;\n",
    "3. Provide commentary on the insights learned from your visualizations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "4d6e2064",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  3.,   5.,   2.,  19.,   8., 234., 211., 183., 231., 181.]),\n",
       " array([0. , 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1. ]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "Y_labels = np.argmax(Y_train, axis=1)\n",
    "Y_labels[0:15]\n",
    "\n",
    "Y_label_name = ['North America', 'Rest of the World', 'Western Europe']\n",
    "\n",
    "maker_region_classes, counts = np.unique(Y_labels, return_counts=True)\n",
    "fig, ax = plt.subplots(6, 1)\n",
    "\n",
    "ax[0].bar(maker_region_classes, counts, tick_label=[f'{Y_label_name[i]}' for i in maker_region_classes])\n",
    "\n",
    "ax[1].scatter(X_train_scaled[:,0], X_train_scaled[:,1])\n",
    "\n",
    "ax[2].scatter(X_train_scaled[:,0], X_train_scaled[:,3])\n",
    "\n",
    "ax[3].scatter(X_train_scaled[:,1], X_train_scaled[:,3])\n",
    "\n",
    "ax[4].hist(X_train_scaled[:,0])\n",
    "\n",
    "ax[5].hist(X_train_scaled[:,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0da9674f",
   "metadata": {},
   "source": [
    "---\n",
    "### Step 4: Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6edcc92d",
   "metadata": {},
   "source": [
    "### <span style=\"color:chocolate\">Exercise 5:</span> Baseline model (10 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b948692c",
   "metadata": {},
   "source": [
    "When dealing with classification problems, a simple baseline is to select the *majority* class (the most common label in the training set) and use it as the prediction for all inputs.\n",
    "\n",
    "1. Implement this baseline and report the accuracy metric on the train data;\n",
    "\n",
    "2. Implement a function that computes the Log Loss (cross-entropy loss) metric and use it to evaluate this baseline on both the train and validation data. Note: reflect on what you know about the original distribution of classes in your training data (Hint: see Assignment 4 - Exercise 8 and ``Module Demos/05 Multiclass Logistic Regression.ipynb`` in bCourses for an example)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "536702e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd5a8365",
   "metadata": {},
   "source": [
    "### <span style=\"color:chocolate\">Exercise 6:</span> Improvement over baseline with Tensorflow (10 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "311dd3ad",
   "metadata": {},
   "source": [
    "Use TensorFlow (TF) to train a multiclass logistic regression model much like you did in Assignment 4. The goal here is to build a ML model to improve over the baseline classifier. You have the flexibility to choose which features to include.\n",
    "\n",
    "With this in mind, complete the following tasks:\n",
    "\n",
    "1. Build and compile a multiclass classification TF model (call it model_tf). Hint: the activation function, the loss, and the evaluation metric are different compared to the binary logistic regression (see ``Module Demos/05 Multiclass Logistic Regression.ipynb`` in bCourses for an example). Set learning_rate = 0.0001 and optimizer = SGD.\n",
    "2. Train model_tf using the training dataset and pass the validation data for validation. Set num_epochs = 10 and batch_size = 32.\n",
    "3. Generate a plot (for the training and validation data) with the loss values on the y-axis and the epoch number on the x-axis for visualization. Make sure to include axes name and title.\n",
    "\n",
    "If instructions for any other hyperparameters are not provided here, you are free to select your own or use the default settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d1e7538",
   "metadata": {},
   "outputs": [],
   "source": [
    "# My own implementation - to keep\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4bf162e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7872617",
   "metadata": {},
   "source": [
    "---\n",
    "### Step 5: Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29cd6bec",
   "metadata": {},
   "source": [
    "### <span style=\"color:chocolate\">Exercise 7:</span> Choosing hyperparameters (10 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97a6c715",
   "metadata": {},
   "source": [
    "1. Fine-tune the **learning rate**, **number of epochs**, and **batch size** hyperparameters of *model_tf* to determine the setup that yields the most optimal generalization performance. Feel free to explore various values for these hyperparameters. Hint: you can manually test different hyperparameter values or you can use the [Keras Tuner](https://www.tensorflow.org/tutorials/keras/keras_tuner). \n",
    "\n",
    "After identifying your preferred model configuration, print the following information:\n",
    "\n",
    "2. The first five learned parameters of the model (this should include the bias term);\n",
    "3. The loss at the final epoch on both the training and validation datasets;\n",
    "4. The percentage difference between the losses observed on the training and validation datasets.\n",
    "5. Compare the training/validation loss of the TensorFlow model (model_tf) with the baseline model's loss. Does the TensorFlow model demonstrate an improvement over the baseline model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "fb087a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "\n",
    "def build_model(num_features, learning_rate):\n",
    "    \"\"\"Build a TF multi-class logistic regression model using Keras.\n",
    "\n",
    "    Args:\n",
    "        num_features: The number of input features.\n",
    "        learning_rate: The desired learning rate for SGD.\n",
    "\n",
    "    Returns:\n",
    "        model: A tf.keras model (graph).\n",
    "    \"\"\"\n",
    "    # Clear previous models and set a random seed\n",
    "    tf.keras.backend.clear_session()\n",
    "    tf.random.set_seed(0)\n",
    "\n",
    "    # Build the model\n",
    "    model = tf.keras.Sequential()\n",
    "\n",
    "\n",
    "        # 🔹 First Hidden Layer (128 nodes, ReLU activation)\n",
    "    model.add(tf.keras.layers.Dense(\n",
    "        units=128,                     # Number of neurons\n",
    "        input_shape=(num_features,),   # Input shape (features)\n",
    "        activation='relu',             # ReLU activation for hidden layers\n",
    "        kernel_initializer='he_normal' # Recommended for ReLU\n",
    "    ))\n",
    "\n",
    "    # 🔹 Second Hidden Layer (64 nodes)\n",
    "    model.add(tf.keras.layers.Dense(\n",
    "        units=64,\n",
    "        activation='relu'\n",
    "    ))\n",
    "\n",
    "    # 🔹 Output Layer (3 nodes for 3-class classification)\n",
    "    model.add(tf.keras.layers.Dense(\n",
    "        units=3,         \n",
    "        activation='softmax'  # Multi-class classification\n",
    "    ))\n",
    "\n",
    "#   model.add(tf.keras.layers.Dense(\n",
    "#       units=3,                   # Output dimension = number of classes (3)\n",
    "#       input_shape=(num_features,),  # Input features\n",
    "#       use_bias=True,               # Use bias term\n",
    "#       activation='softmax',        # Multi-class classification\n",
    "#       kernel_initializer='ones',  # Initialize weights to 1\n",
    "#       bias_initializer='ones',    # Initialize bias to 1\n",
    "#   ))\n",
    "\n",
    "    # Use SGD optimizer\n",
    "    optimizer = tf.keras.optimizers.SGD(learning_rate)\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(optimizer=optimizer,\n",
    "                  loss='categorical_crossentropy',  # Multi-class classification loss\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "84033402",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.2627 - loss: 1.2235 - val_accuracy: 0.2897 - val_loss: 1.1456\n",
      "Epoch 2/150\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3395 - loss: 1.1193 - val_accuracy: 0.4513 - val_loss: 1.0786\n",
      "Epoch 3/150\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4294 - loss: 1.0772 - val_accuracy: 0.5097 - val_loss: 1.0470\n",
      "Epoch 4/150\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4806 - loss: 1.0585 - val_accuracy: 0.5237 - val_loss: 1.0303\n",
      "Epoch 5/150\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4929 - loss: 1.0489 - val_accuracy: 0.5320 - val_loss: 1.0205\n",
      "Epoch 6/150\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4882 - loss: 1.0432 - val_accuracy: 0.5348 - val_loss: 1.0144\n",
      "Epoch 7/150\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4938 - loss: 1.0394 - val_accuracy: 0.5348 - val_loss: 1.0102\n",
      "Epoch 8/150\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4943 - loss: 1.0365 - val_accuracy: 0.5348 - val_loss: 1.0072\n",
      "Epoch 9/150\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4934 - loss: 1.0342 - val_accuracy: 0.5348 - val_loss: 1.0049\n",
      "Epoch 10/150\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4928 - loss: 1.0322 - val_accuracy: 0.5348 - val_loss: 1.0031\n",
      "Epoch 11/150\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4955 - loss: 1.0305 - val_accuracy: 0.5348 - val_loss: 1.0017\n",
      "Epoch 12/150\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4975 - loss: 1.0290 - val_accuracy: 0.5376 - val_loss: 1.0006\n",
      "Epoch 13/150\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5051 - loss: 1.0276 - val_accuracy: 0.5404 - val_loss: 0.9996\n",
      "Epoch 14/150\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5051 - loss: 1.0265 - val_accuracy: 0.5404 - val_loss: 0.9988\n",
      "Epoch 15/150\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5042 - loss: 1.0255 - val_accuracy: 0.5320 - val_loss: 0.9981\n",
      "Epoch 16/150\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5041 - loss: 1.0246 - val_accuracy: 0.5292 - val_loss: 0.9974\n",
      "Epoch 17/150\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5064 - loss: 1.0238 - val_accuracy: 0.5320 - val_loss: 0.9969\n",
      "Epoch 18/150\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5062 - loss: 1.0230 - val_accuracy: 0.5348 - val_loss: 0.9964\n",
      "Epoch 19/150\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5112 - loss: 1.0223 - val_accuracy: 0.5432 - val_loss: 0.9960\n",
      "Epoch 20/150\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5109 - loss: 1.0217 - val_accuracy: 0.5432 - val_loss: 0.9957\n",
      "Epoch 21/150\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5113 - loss: 1.0211 - val_accuracy: 0.5404 - val_loss: 0.9954\n",
      "Epoch 22/150\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5094 - loss: 1.0206 - val_accuracy: 0.5404 - val_loss: 0.9951\n",
      "Epoch 23/150\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5066 - loss: 1.0201 - val_accuracy: 0.5404 - val_loss: 0.9948\n",
      "Epoch 24/150\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5074 - loss: 1.0197 - val_accuracy: 0.5376 - val_loss: 0.9946\n",
      "Epoch 25/150\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5067 - loss: 1.0192 - val_accuracy: 0.5376 - val_loss: 0.9944\n",
      "Epoch 26/150\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5095 - loss: 1.0188 - val_accuracy: 0.5404 - val_loss: 0.9942\n",
      "Epoch 27/150\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5099 - loss: 1.0185 - val_accuracy: 0.5432 - val_loss: 0.9940\n",
      "Epoch 28/150\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5099 - loss: 1.0181 - val_accuracy: 0.5404 - val_loss: 0.9938\n",
      "Epoch 29/150\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5124 - loss: 1.0178 - val_accuracy: 0.5348 - val_loss: 0.9937\n",
      "Epoch 30/150\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5179 - loss: 1.0174 - val_accuracy: 0.5320 - val_loss: 0.9935\n",
      "Epoch 31/150\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5258 - loss: 1.0171 - val_accuracy: 0.5320 - val_loss: 0.9934\n",
      "Epoch 32/150\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5270 - loss: 1.0168 - val_accuracy: 0.5348 - val_loss: 0.9932\n",
      "Epoch 33/150\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5294 - loss: 1.0166 - val_accuracy: 0.5348 - val_loss: 0.9931\n",
      "Epoch 34/150\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5299 - loss: 1.0163 - val_accuracy: 0.5376 - val_loss: 0.9930\n",
      "Epoch 35/150\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5299 - loss: 1.0160 - val_accuracy: 0.5376 - val_loss: 0.9929\n",
      "Epoch 36/150\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5294 - loss: 1.0158 - val_accuracy: 0.5376 - val_loss: 0.9928\n",
      "Epoch 37/150\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5285 - loss: 1.0155 - val_accuracy: 0.5376 - val_loss: 0.9926\n",
      "Epoch 38/150\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5285 - loss: 1.0153 - val_accuracy: 0.5348 - val_loss: 0.9925\n",
      "Epoch 39/150\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5267 - loss: 1.0151 - val_accuracy: 0.5348 - val_loss: 0.9925\n",
      "Epoch 40/150\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5227 - loss: 1.0149 - val_accuracy: 0.5348 - val_loss: 0.9924\n",
      "Epoch 41/150\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5251 - loss: 1.0147 - val_accuracy: 0.5376 - val_loss: 0.9923\n",
      "Epoch 42/150\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5239 - loss: 1.0145 - val_accuracy: 0.5376 - val_loss: 0.9922\n",
      "Epoch 43/150\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5232 - loss: 1.0143 - val_accuracy: 0.5376 - val_loss: 0.9921\n",
      "Epoch 44/150\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5232 - loss: 1.0141 - val_accuracy: 0.5376 - val_loss: 0.9920\n",
      "Epoch 45/150\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5269 - loss: 1.0139 - val_accuracy: 0.5376 - val_loss: 0.9919\n",
      "Epoch 46/150\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5269 - loss: 1.0138 - val_accuracy: 0.5376 - val_loss: 0.9919\n",
      "Epoch 47/150\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5269 - loss: 1.0136 - val_accuracy: 0.5376 - val_loss: 0.9918\n",
      "Epoch 48/150\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5273 - loss: 1.0134 - val_accuracy: 0.5376 - val_loss: 0.9917\n",
      "Epoch 49/150\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5273 - loss: 1.0133 - val_accuracy: 0.5376 - val_loss: 0.9916\n",
      "Epoch 50/150\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5273 - loss: 1.0131 - val_accuracy: 0.5376 - val_loss: 0.9916\n",
      "Epoch 51/150\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5302 - loss: 1.0130 - val_accuracy: 0.5376 - val_loss: 0.9915\n",
      "Epoch 52/150\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5302 - loss: 1.0129 - val_accuracy: 0.5376 - val_loss: 0.9914\n",
      "Epoch 53/150\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5301 - loss: 1.0127 - val_accuracy: 0.5376 - val_loss: 0.9913\n",
      "Epoch 54/150\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5265 - loss: 1.0126 - val_accuracy: 0.5376 - val_loss: 0.9912\n",
      "Epoch 55/150\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5265 - loss: 1.0125 - val_accuracy: 0.5376 - val_loss: 0.9912\n",
      "Epoch 56/150\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5258 - loss: 1.0124 - val_accuracy: 0.5376 - val_loss: 0.9911\n",
      "Epoch 57/150\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5254 - loss: 1.0123 - val_accuracy: 0.5376 - val_loss: 0.9910\n",
      "Epoch 58/150\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5254 - loss: 1.0121 - val_accuracy: 0.5320 - val_loss: 0.9910\n",
      "Epoch 59/150\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5254 - loss: 1.0120 - val_accuracy: 0.5348 - val_loss: 0.9909\n",
      "Epoch 60/150\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5254 - loss: 1.0119 - val_accuracy: 0.5320 - val_loss: 0.9909\n",
      "Epoch 61/150\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5254 - loss: 1.0118 - val_accuracy: 0.5320 - val_loss: 0.9908\n",
      "Epoch 62/150\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5259 - loss: 1.0117 - val_accuracy: 0.5320 - val_loss: 0.9908\n",
      "Epoch 63/150\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5259 - loss: 1.0116 - val_accuracy: 0.5320 - val_loss: 0.9907\n",
      "Epoch 64/150\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5259 - loss: 1.0115 - val_accuracy: 0.5320 - val_loss: 0.9907\n",
      "Epoch 65/150\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5264 - loss: 1.0115 - val_accuracy: 0.5320 - val_loss: 0.9906\n",
      "Epoch 66/150\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5255 - loss: 1.0114 - val_accuracy: 0.5320 - val_loss: 0.9906\n",
      "Epoch 67/150\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5255 - loss: 1.0113 - val_accuracy: 0.5320 - val_loss: 0.9905\n",
      "Epoch 68/150\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5255 - loss: 1.0112 - val_accuracy: 0.5320 - val_loss: 0.9905\n",
      "Epoch 69/150\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5255 - loss: 1.0111 - val_accuracy: 0.5320 - val_loss: 0.9905\n",
      "Epoch 70/150\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5255 - loss: 1.0110 - val_accuracy: 0.5348 - val_loss: 0.9904\n",
      "Epoch 71/150\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5248 - loss: 1.0109 - val_accuracy: 0.5348 - val_loss: 0.9904\n",
      "Epoch 72/150\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5248 - loss: 1.0109 - val_accuracy: 0.5348 - val_loss: 0.9903\n",
      "Epoch 73/150\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5248 - loss: 1.0108 - val_accuracy: 0.5348 - val_loss: 0.9903\n",
      "Epoch 74/150\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5248 - loss: 1.0107 - val_accuracy: 0.5348 - val_loss: 0.9902\n",
      "Epoch 75/150\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5248 - loss: 1.0107 - val_accuracy: 0.5348 - val_loss: 0.9902\n",
      "Epoch 76/150\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5248 - loss: 1.0106 - val_accuracy: 0.5348 - val_loss: 0.9901\n",
      "Epoch 77/150\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5248 - loss: 1.0105 - val_accuracy: 0.5348 - val_loss: 0.9901\n",
      "Epoch 78/150\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5248 - loss: 1.0105 - val_accuracy: 0.5348 - val_loss: 0.9901\n",
      "Epoch 79/150\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5248 - loss: 1.0104 - val_accuracy: 0.5348 - val_loss: 0.9900\n",
      "Epoch 80/150\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5248 - loss: 1.0103 - val_accuracy: 0.5348 - val_loss: 0.9900\n",
      "Epoch 81/150\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5248 - loss: 1.0103 - val_accuracy: 0.5348 - val_loss: 0.9900\n",
      "Epoch 82/150\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5248 - loss: 1.0102 - val_accuracy: 0.5348 - val_loss: 0.9899\n",
      "Epoch 83/150\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5245 - loss: 1.0102 - val_accuracy: 0.5348 - val_loss: 0.9899\n",
      "Epoch 84/150\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5245 - loss: 1.0101 - val_accuracy: 0.5348 - val_loss: 0.9899\n",
      "Epoch 85/150\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5245 - loss: 1.0101 - val_accuracy: 0.5348 - val_loss: 0.9898\n",
      "Epoch 86/150\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5245 - loss: 1.0100 - val_accuracy: 0.5348 - val_loss: 0.9898\n",
      "Epoch 87/150\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5245 - loss: 1.0100 - val_accuracy: 0.5348 - val_loss: 0.9898\n",
      "Epoch 88/150\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5245 - loss: 1.0099 - val_accuracy: 0.5348 - val_loss: 0.9898\n",
      "Epoch 89/150\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5245 - loss: 1.0099 - val_accuracy: 0.5320 - val_loss: 0.9897\n",
      "Epoch 90/150\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5245 - loss: 1.0098 - val_accuracy: 0.5320 - val_loss: 0.9897\n",
      "Epoch 91/150\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5245 - loss: 1.0098 - val_accuracy: 0.5320 - val_loss: 0.9897\n",
      "Epoch 92/150\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5245 - loss: 1.0097 - val_accuracy: 0.5320 - val_loss: 0.9896\n",
      "Epoch 93/150\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5245 - loss: 1.0097 - val_accuracy: 0.5320 - val_loss: 0.9896\n",
      "Epoch 94/150\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5245 - loss: 1.0096 - val_accuracy: 0.5320 - val_loss: 0.9896\n",
      "Epoch 95/150\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5245 - loss: 1.0096 - val_accuracy: 0.5320 - val_loss: 0.9896\n",
      "Epoch 96/150\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5245 - loss: 1.0095 - val_accuracy: 0.5320 - val_loss: 0.9895\n",
      "Epoch 97/150\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5245 - loss: 1.0095 - val_accuracy: 0.5320 - val_loss: 0.9895\n",
      "Epoch 98/150\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5245 - loss: 1.0095 - val_accuracy: 0.5320 - val_loss: 0.9895\n",
      "Epoch 99/150\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5245 - loss: 1.0094 - val_accuracy: 0.5320 - val_loss: 0.9895\n",
      "Epoch 100/150\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5245 - loss: 1.0094 - val_accuracy: 0.5320 - val_loss: 0.9894\n",
      "Epoch 101/150\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5245 - loss: 1.0093 - val_accuracy: 0.5320 - val_loss: 0.9894\n",
      "Epoch 102/150\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5245 - loss: 1.0093 - val_accuracy: 0.5320 - val_loss: 0.9894\n",
      "Epoch 103/150\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5245 - loss: 1.0092 - val_accuracy: 0.5320 - val_loss: 0.9893\n",
      "Epoch 104/150\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5245 - loss: 1.0092 - val_accuracy: 0.5320 - val_loss: 0.9893\n",
      "Epoch 105/150\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5245 - loss: 1.0092 - val_accuracy: 0.5320 - val_loss: 0.9893\n",
      "Epoch 106/150\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5245 - loss: 1.0091 - val_accuracy: 0.5320 - val_loss: 0.9893\n",
      "Epoch 107/150\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5245 - loss: 1.0091 - val_accuracy: 0.5320 - val_loss: 0.9892\n",
      "Epoch 108/150\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5245 - loss: 1.0090 - val_accuracy: 0.5320 - val_loss: 0.9892\n",
      "Epoch 109/150\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5245 - loss: 1.0090 - val_accuracy: 0.5320 - val_loss: 0.9892\n",
      "Epoch 110/150\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5245 - loss: 1.0090 - val_accuracy: 0.5320 - val_loss: 0.9892\n",
      "Epoch 111/150\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5245 - loss: 1.0089 - val_accuracy: 0.5320 - val_loss: 0.9891\n",
      "Epoch 112/150\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5245 - loss: 1.0089 - val_accuracy: 0.5320 - val_loss: 0.9891\n",
      "Epoch 113/150\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5245 - loss: 1.0089 - val_accuracy: 0.5320 - val_loss: 0.9891\n",
      "Epoch 114/150\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5245 - loss: 1.0088 - val_accuracy: 0.5320 - val_loss: 0.9891\n",
      "Epoch 115/150\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5245 - loss: 1.0088 - val_accuracy: 0.5320 - val_loss: 0.9890\n",
      "Epoch 116/150\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5245 - loss: 1.0088 - val_accuracy: 0.5320 - val_loss: 0.9890\n",
      "Epoch 117/150\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5245 - loss: 1.0087 - val_accuracy: 0.5320 - val_loss: 0.9890\n",
      "Epoch 118/150\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5245 - loss: 1.0087 - val_accuracy: 0.5320 - val_loss: 0.9890\n",
      "Epoch 119/150\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5245 - loss: 1.0087 - val_accuracy: 0.5320 - val_loss: 0.9890\n",
      "Epoch 120/150\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5245 - loss: 1.0086 - val_accuracy: 0.5320 - val_loss: 0.9889\n",
      "Epoch 121/150\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5245 - loss: 1.0086 - val_accuracy: 0.5320 - val_loss: 0.9889\n",
      "Epoch 122/150\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5245 - loss: 1.0086 - val_accuracy: 0.5292 - val_loss: 0.9889\n",
      "Epoch 123/150\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5245 - loss: 1.0085 - val_accuracy: 0.5292 - val_loss: 0.9889\n",
      "Epoch 124/150\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5245 - loss: 1.0085 - val_accuracy: 0.5292 - val_loss: 0.9889\n",
      "Epoch 125/150\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5245 - loss: 1.0085 - val_accuracy: 0.5292 - val_loss: 0.9889\n",
      "Epoch 126/150\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5245 - loss: 1.0084 - val_accuracy: 0.5292 - val_loss: 0.9888\n",
      "Epoch 127/150\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5245 - loss: 1.0084 - val_accuracy: 0.5292 - val_loss: 0.9888\n",
      "Epoch 128/150\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5241 - loss: 1.0084 - val_accuracy: 0.5292 - val_loss: 0.9888\n",
      "Epoch 129/150\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5241 - loss: 1.0083 - val_accuracy: 0.5292 - val_loss: 0.9888\n",
      "Epoch 130/150\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5241 - loss: 1.0083 - val_accuracy: 0.5292 - val_loss: 0.9888\n",
      "Epoch 131/150\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5241 - loss: 1.0083 - val_accuracy: 0.5292 - val_loss: 0.9888\n",
      "Epoch 132/150\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5241 - loss: 1.0083 - val_accuracy: 0.5292 - val_loss: 0.9888\n",
      "Epoch 133/150\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5241 - loss: 1.0082 - val_accuracy: 0.5292 - val_loss: 0.9887\n",
      "Epoch 134/150\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5241 - loss: 1.0082 - val_accuracy: 0.5292 - val_loss: 0.9887\n",
      "Epoch 135/150\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5241 - loss: 1.0082 - val_accuracy: 0.5292 - val_loss: 0.9887\n",
      "Epoch 136/150\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5241 - loss: 1.0081 - val_accuracy: 0.5292 - val_loss: 0.9887\n",
      "Epoch 137/150\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5241 - loss: 1.0081 - val_accuracy: 0.5292 - val_loss: 0.9887\n",
      "Epoch 138/150\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5241 - loss: 1.0081 - val_accuracy: 0.5292 - val_loss: 0.9887\n",
      "Epoch 139/150\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5241 - loss: 1.0081 - val_accuracy: 0.5292 - val_loss: 0.9886\n",
      "Epoch 140/150\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5241 - loss: 1.0080 - val_accuracy: 0.5292 - val_loss: 0.9886\n",
      "Epoch 141/150\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5241 - loss: 1.0080 - val_accuracy: 0.5292 - val_loss: 0.9886\n",
      "Epoch 142/150\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5241 - loss: 1.0080 - val_accuracy: 0.5292 - val_loss: 0.9886\n",
      "Epoch 143/150\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5241 - loss: 1.0080 - val_accuracy: 0.5292 - val_loss: 0.9886\n",
      "Epoch 144/150\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5241 - loss: 1.0079 - val_accuracy: 0.5292 - val_loss: 0.9886\n",
      "Epoch 145/150\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5241 - loss: 1.0079 - val_accuracy: 0.5292 - val_loss: 0.9886\n",
      "Epoch 146/150\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5241 - loss: 1.0079 - val_accuracy: 0.5292 - val_loss: 0.9885\n",
      "Epoch 147/150\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5241 - loss: 1.0078 - val_accuracy: 0.5292 - val_loss: 0.9885\n",
      "Epoch 148/150\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5241 - loss: 1.0078 - val_accuracy: 0.5292 - val_loss: 0.9885\n",
      "Epoch 149/150\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5246 - loss: 1.0078 - val_accuracy: 0.5292 - val_loss: 0.9885\n",
      "Epoch 150/150\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5246 - loss: 1.0078 - val_accuracy: 0.5292 - val_loss: 0.9885\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(0)\n",
    "# 2. Build and compile model\n",
    "# YOUR CODE HERE\n",
    "\n",
    "# Build and compile\n",
    "model_tf = build_model(num_features=X_train_scaled.shape[1],\n",
    "                       learning_rate=0.001)\n",
    "\n",
    "# 3. Fit the model\n",
    "# YOUR CODE HERE\n",
    "# Fit the model with specified hyperparameters\n",
    "history = model_tf.fit(X_train_scaled, Y_train,\n",
    "             epochs=150,\n",
    "             batch_size=32,\n",
    "             validation_data=(X_val_scaled, Y_val),\n",
    "             verbose=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d8b941b",
   "metadata": {},
   "source": [
    "---\n",
    "### Step 6: Evaluation and generalization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1640c795",
   "metadata": {},
   "source": [
    "### <span style=\"color:chocolate\">Exercise 8:</span> Compute metrics (10 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb78fc49",
   "metadata": {},
   "source": [
    "Now that you've determined the optimal set of hyperparameters, it's time to evaluate your optimized model on the test data to gauge its performance in real-world scenarios, commonly known as inference."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52a452f0",
   "metadata": {},
   "source": [
    "1. Calculate aggregate accuracy on both train and test datasets. Note: you will need to convert the vector of predicted probabilities to a class label using the argmax operation. Hint: You can utilize the <span style=\"color:chocolate\">model.predict()</span> method provided by tf.keras. and the <span style=\"color:chocolate\">np.max()</span> method available in NumPy.\n",
    "\n",
    "2. Does the model demonstrate strong aggregate generalization capabilities? Provide an explanation based on your accuracy observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "97a896a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46219440",
   "metadata": {},
   "source": [
    "### <span style=\"color:chocolate\">Exercise 9:</span> Additional metrics (10 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd95a071",
   "metadata": {},
   "source": [
    "Using the test dataset:\n",
    "\n",
    "1. Plot the confusion matrix. Identify which class the model confuses the most.\n",
    "\n",
    "2. Determine which class has the lowest precision. What is the precision? Which class is the largest source of false positives?\n",
    "\n",
    "3. Determine which class has the lowest recall. What is the recall? Which class is the largest source of false negatives?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "42733dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7599dc56",
   "metadata": {},
   "source": [
    "----\n",
    "#### <span style=\"color:chocolate\">Additional practice question</span> (not graded)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15e04ef4",
   "metadata": {},
   "source": [
    "Following the approach in Assignment 4 - Exercise 12, evaluate whether your model shows any signs of unfairness. Explain your findings and propose suggestions for improvement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d47f2de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
